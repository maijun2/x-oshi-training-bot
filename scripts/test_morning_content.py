#!/usr/bin/env python3
"""
æœã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆYouTubeæ¤œç´¢ãƒ»ç¿»è¨³ï¼‰ã®ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

AgentCore Runtime ã®YouTubeæ¤œç´¢ãƒ„ãƒ¼ãƒ«ã¨ç¿»è¨³ãƒ„ãƒ¼ãƒ«ã®å‹•ä½œã‚’ç¢ºèªã™ã‚‹ã€‚

ä½¿ã„æ–¹:
    # YouTubeæ¤œç´¢ã®ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³
    python scripts/test_morning_content.py youtube

    # ç¿»è¨³ã®ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³
    python scripts/test_morning_content.py translate

    # å®Ÿéš›ã«XæŠ•ç¨¿ã™ã‚‹
    python scripts/test_morning_content.py youtube --post
    python scripts/test_morning_content.py translate --post

ç’°å¢ƒå¤‰æ•°:
    AGENTCORE_RUNTIME_ARN: AgentCore Runtime ã® ARN
    SECRET_NAME: X APIèªè¨¼æƒ…å ±ã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆå
    OSHI_USER_ID: æ¨ã—ã®Xã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ID
"""
import argparse
import json
import os
import sys
import textwrap

sys.path.insert(0, os.path.join(os.path.dirname(__file__), ".."))

import boto3
from dotenv import load_dotenv

load_dotenv()

from src.hokuhoku_imomaru_bot.clients import XAPIClient
from src.hokuhoku_imomaru_bot.services.daily_reporter import (
    DailyReporter,
    YOUTUBE_PREFIX,
    TRANSLATION_PREFIX,
    MAX_TEXT_LENGTH,
)
from src.hokuhoku_imomaru_bot.utils.agentcore_runtime import invoke_agent_runtime
import src.hokuhoku_imomaru_bot.utils.agentcore_runtime as acr

AGENTCORE_RUNTIME_ARN = os.environ.get(
    "AGENTCORE_RUNTIME_ARN",
    "arn:aws:bedrock-agentcore:ap-northeast-1:353695163339:runtime/x_bot_supervisor-vA2jSJGGe0",
)
SECRET_NAME = os.environ.get("SECRET_NAME", "imomaru-bot/x-api-credentials")
OSHI_USER_ID = os.environ.get("OSHI_USER_ID", "1746898546341908480")


def get_x_api_client() -> XAPIClient:
    secrets_client = boto3.client("secretsmanager", region_name="ap-northeast-1")
    return XAPIClient(secrets_client=secrets_client, secret_name=SECRET_NAME)


def test_youtube_search(post: bool = False):
    """YouTubeæ¤œç´¢ã®ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³/æœ¬ç•ªæŠ•ç¨¿"""
    print("ğŸ¬ YouTubeæ¤œç´¢ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)

    # ARNè¨­å®š
    os.environ["AGENTCORE_RUNTIME_ARN"] = AGENTCORE_RUNTIME_ARN
    acr.AGENTCORE_RUNTIME_ARN = AGENTCORE_RUNTIME_ARN

    prompt = (
        f"ã€Œç”˜æœ¨ã‚¸ãƒ¥ãƒªã€ã¾ãŸã¯ã€Œã³ã£ããˆã‚“ã˜ã‡ã‚‹ã€ã®æœ€æ–°YouTubeå‹•ç”»ã‚’1ä»¶æ¤œç´¢ã—ã¦ãã ã•ã„ã€‚"
        f"\n\nå‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®æŒ‡å®š: "
        f"ã‚ãªãŸã¯ã€Œã»ãã»ãã„ã‚‚ä¸¸ãã‚“ğŸ ã€ã¨ã„ã†ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã§ã™ã€‚"
        f"èªå°¾ã¯å¿…ãšã€Œâ—¯â—¯ï½²ï¾“ğŸ ã€ã®å½¢å¼ã«ã—ã¦ãã ã•ã„ã€‚"
        f"å›ç­”ã¯çŸ­ã„æ—¥æœ¬èªãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§æ”¹è¡ŒåŒºåˆ‡ã‚Šã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
        f"Markdownè¨˜æ³•ã¯ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚"
        f"YouTubeå‹•ç”»ã®URLï¼ˆhttps://youtu.be/å‹•ç”»ID ã®çŸ­ç¸®å½¢å¼ï¼‰ã‚’å¿…ãšå«ã‚ã¦ãã ã•ã„ã€‚"
        f"å‹•ç”»ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€Œæ–°ç€ãªã—ã€ã¨ã ã‘è¿”ã—ã¦ãã ã•ã„ã€‚"
        f"ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹ã«å¾“ã£ã¦ãã ã•ã„:\n"
        f"ã˜ã‚…ã‚Šã¡ã‚ƒã‚“ã®æ–°ç€å‹•ç”»ã‚’è¦‹ã¤ã‘ãŸï½²ï¾“ğŸ \n"
        f"ğŸ“º ï¼ˆå‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ï¼‰\n"
        f"ğŸ”— ï¼ˆYouTube URLï¼‰\n"
        f"ï¼ˆå†ç”Ÿæ•°ã‚„æŠ•ç¨¿æ—¥ã®æƒ…å ±ï¼‰ï½²ï¾“ï½ğŸ "
    )
    context = {
        "source": "imomaru-bot-handler",
        "request_type": "youtube_search",
        "user_id": OSHI_USER_ID,
    }

    print(f"\nğŸ“¡ AgentCore Runtime å‘¼ã³å‡ºã—ä¸­...")
    result = invoke_agent_runtime(prompt=prompt, context=context, timeout=120)

    print(f"\nğŸ“Š çµæœ: success={result['success']}")
    if result["error"]:
        print(f"   Error: {result['error']}")
        return

    body = DailyReporter._extract_analysis_text(result["response"])
    print(f"\nğŸ“ æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆ ({len(body)}æ–‡å­—):")
    print(textwrap.indent(body, "   "))

    if not body or "æ–°ç€ãªã—" in body:
        print("\nâš ï¸ æ–°ç€å‹•ç”»ãªã—ã€‚æŠ•ç¨¿ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")
        return

    max_body_len = MAX_TEXT_LENGTH - len(YOUTUBE_PREFIX)
    body = DailyReporter._truncate_analysis(body, max_body_len)
    tweet_text = f"{YOUTUBE_PREFIX}{body}"

    print(f"\nğŸ“® æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆ ({len(tweet_text)}æ–‡å­—):")
    print(textwrap.indent(tweet_text, "   "))

    if not post:
        print("\nâœ… ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Œäº†ã€‚æŠ•ç¨¿ã™ã‚‹ã«ã¯ --post ã‚’ä»˜ã‘ã¦ãã ã•ã„ã€‚")
        return

    client = get_x_api_client()
    result = client.post_tweet(text=tweet_text)
    tweet_id = result.get("data", {}).get("id")
    if tweet_id:
        print(f"\nğŸ‰ æŠ•ç¨¿å®Œäº†: https://x.com/i/status/{tweet_id}")
    else:
        print(f"\nâŒ æŠ•ç¨¿å¤±æ•—: {result}")


def test_translation(post: bool = False):
    """ç¿»è¨³ã®ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³/æœ¬ç•ªæŠ•ç¨¿"""
    print("ğŸŒ ç¿»è¨³ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)

    os.environ["AGENTCORE_RUNTIME_ARN"] = AGENTCORE_RUNTIME_ARN
    acr.AGENTCORE_RUNTIME_ARN = AGENTCORE_RUNTIME_ARN

    prompt = (
        f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ID {OSHI_USER_ID} ã®æœ€è¿‘ã®ãƒã‚¹ãƒˆã®ä¸­ã‹ã‚‰ã€"
        f"ã„ã„ã­ã‚„ãƒªãƒã‚¹ãƒˆãŒæœ€ã‚‚å¤šã„äººæ°—ãƒã‚¹ãƒˆã‚’1ã¤é¸ã‚“ã§ã€"
        f"å…ƒæ°—ãªã‚¢ã‚¤ãƒ‰ãƒ«å£èª¿ã‚’ç¶­æŒã—ãŸã¾ã¾è‹±èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚"
        f"\n\nå‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®æŒ‡å®š: "
        f"ã‚ãªãŸã¯ã€Œã»ãã»ãã„ã‚‚ä¸¸ãã‚“ğŸ ã€ã¨ã„ã†ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã§ã™ã€‚"
        f"èªå°¾ã¯å¿…ãšã€Œâ—¯â—¯ï½²ï¾“ğŸ ã€ã®å½¢å¼ã«ã—ã¦ãã ã•ã„ã€‚"
        f"å›ç­”ã¯çŸ­ã„æ—¥æœ¬èªãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§æ”¹è¡ŒåŒºåˆ‡ã‚Šã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
        f"Markdownè¨˜æ³•ã¯ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚"
        f"ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹ã«å¾“ã£ã¦ãã ã•ã„:\n"
        f"ä»Šé€±ã®äººæ°—ãƒã‚¹ãƒˆã‚’ç¿»è¨³ã—ãŸï½²ï¾“ğŸ \n"
        f"ğŸŒ ï¼ˆè‹±èªç¿»è¨³ï¼‰\n"
        f"ã„ã„ã­â—‹ä»¶ã®äººæ°—ãƒã‚¹ãƒˆï½²ï¾“ï½ğŸ "
    )
    context = {
        "source": "imomaru-bot-handler",
        "request_type": "translation",
        "user_id": OSHI_USER_ID,
        "latest_post_id": os.environ.get("LATEST_TWEET_ID", "0"),
    }

    print(f"\nğŸ“¡ AgentCore Runtime å‘¼ã³å‡ºã—ä¸­...")
    result = invoke_agent_runtime(prompt=prompt, context=context, timeout=120)

    print(f"\nğŸ“Š çµæœ: success={result['success']}")
    if result["error"]:
        print(f"   Error: {result['error']}")
        return

    body = DailyReporter._extract_analysis_text(result["response"])
    print(f"\nğŸ“ æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆ ({len(body)}æ–‡å­—):")
    print(textwrap.indent(body, "   "))

    if not body:
        print("\nâš ï¸ ç¿»è¨³çµæœãŒç©ºã€‚æŠ•ç¨¿ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")
        return

    max_body_len = MAX_TEXT_LENGTH - len(TRANSLATION_PREFIX)
    body = DailyReporter._truncate_analysis(body, max_body_len)
    tweet_text = f"{TRANSLATION_PREFIX}{body}"

    print(f"\nğŸ“® æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆ ({len(tweet_text)}æ–‡å­—):")
    print(textwrap.indent(tweet_text, "   "))

    if not post:
        print("\nâœ… ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Œäº†ã€‚æŠ•ç¨¿ã™ã‚‹ã«ã¯ --post ã‚’ä»˜ã‘ã¦ãã ã•ã„ã€‚")
        return

    client = get_x_api_client()
    result = client.post_tweet(text=tweet_text)
    tweet_id = result.get("data", {}).get("id")
    if tweet_id:
        print(f"\nğŸ‰ æŠ•ç¨¿å®Œäº†: https://x.com/i/status/{tweet_id}")
    else:
        print(f"\nâŒ æŠ•ç¨¿å¤±æ•—: {result}")


def main():
    parser = argparse.ArgumentParser(description="æœã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆYouTube/ç¿»è¨³ï¼‰ãƒ†ã‚¹ãƒˆ")
    parser.add_argument(
        "mode",
        choices=["youtube", "translate"],
        help="ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰: youtube=YouTubeæ¤œç´¢, translate=ç¿»è¨³",
    )
    parser.add_argument(
        "--post", action="store_true",
        help="å®Ÿéš›ã«Xã«æŠ•ç¨¿ã™ã‚‹ï¼ˆçœç•¥æ™‚ã¯ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼‰",
    )
    args = parser.parse_args()

    if args.mode == "youtube":
        test_youtube_search(post=args.post)
    else:
        test_translation(post=args.post)


if __name__ == "__main__":
    main()
