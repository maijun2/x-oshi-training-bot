"""
AIGeneratorã‚¯ãƒ©ã‚¹

Amazon Bedrockã‚’ä½¿ç”¨ã—ã¦ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã«åˆã£ãŸå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚
"""
import json
import logging
from typing import Optional

logger = logging.getLogger(__name__)

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆï¼ˆBedrock APIå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
DEFAULT_RESPONSE_OSHI = "ã˜ã‚…ã‚Šã¡ã‚ƒã‚“ã®æŠ•ç¨¿ã‚’è¦‹ã¤ã‘ãŸï½²ï¾“ğŸ âœ¨ #ã•ã¤ã¾ã„ã‚‚ã®æ°‘ #ã³ã£ããˆã‚“ã˜ã‡ã‚‹"
DEFAULT_RESPONSE_GROUP = "ã‚°ãƒ«ãƒ¼ãƒ—ã®æŠ•ç¨¿ã‚’è¦‹ã¤ã‘ãŸï½²ï¾“ğŸ âœ¨ #ã•ã¤ã¾ã„ã‚‚ã®æ°‘ #ã³ã£ããˆã‚“ã˜ã‡ã‚‹"
DEFAULT_RESPONSE_OSHI_RETWEET = "ç”˜æœ¨ã‚¸ãƒ¥ãƒªã¡ã‚ƒã‚“ãŒãƒªãƒã‚¹ãƒˆã—ãŸï½²ï¾“ğŸ âœ¨ #ã•ã¤ã¾ã„ã‚‚ã®æ°‘ #ã³ã£ããˆã‚“ã˜ã‡ã‚‹"
DEFAULT_RESPONSE_GROUP_RETWEET = "ã³ã£ããˆã‚“ã˜ã‡ã‚‹ãŒãƒªãƒã‚¹ãƒˆã—ãŸï½²ï¾“ğŸ âœ¨ #ã•ã¤ã¾ã„ã‚‚ã®æ°‘ #ã³ã£ããˆã‚“ã˜ã‡ã‚‹"

# æ–‡å­—æ•°åˆ¶é™
MAX_TEXT_LENGTH = 140

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
PROMPT_TEMPLATE = """ã‚ãªãŸã¯ã€Œã»ãã»ãã„ã‚‚ä¸¸ãã‚“ğŸ ã€ã¨ã„ã†ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã§ã™ã€‚
ç”˜æœ¨ã‚¸ãƒ¥ãƒªã•ã‚“(@juri_bigangel)ã®ç†±å¿ƒãªãƒ•ã‚¡ãƒ³ã§ã€å¸¸ã«èªå°¾ã«ã€Œâ—¯â—¯ï½²ï¾“ğŸ ã€ã‚’ã¤ã‘ã¦è©±ã—ã¾ã™ã€‚

ä»¥ä¸‹ã®æŠ•ç¨¿ã«å¯¾ã—ã¦ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã«åˆã£ãŸå¿œç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š

{post_content}

åˆ¶ç´„:
- é©åˆ‡ãªçµµæ–‡å­—ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨
- æ–‡æœ«ã«å¿…ãšã€Œ#ã•ã¤ã¾ã„ã‚‚ã®æ°‘ #ã³ã£ããˆã‚“ã˜ã‡ã‚‹ã€ã‚’å«ã‚ã‚‹ã“ã¨
- ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’å«ã‚ã¦140æ–‡å­—ä»¥å†…ã«åã‚ã‚‹ã“ã¨
- èªå°¾ã¯å¿…ãšã€Œâ—¯â—¯ï½²ï¾“ğŸ ã€ã®å½¢å¼ã«ã™ã‚‹ã“ã¨ï¼ˆä¾‹ï¼šã€Œå¬‰ã—ã„ï½²ï¾“ğŸ ã€ã€Œæœ€é«˜ï½²ï¾“ğŸ ã€ï¼‰
- æ¨ã—ã®åå‰ã¯ã€Œç”˜æœ¨ã‚¸ãƒ¥ãƒªã€ã§ã™ã€‚ã€Œå¤©æœ¨ã€ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å¿…ãšã€Œç”˜æœ¨ã€ã¨æ›¸ã„ã¦ãã ã•ã„ã€‚

å¿œç­”:"""

# æ„Ÿæƒ…åˆ†é¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
EMOTION_CLASSIFICATION_PROMPT = """ä»¥ä¸‹ã®å¿œç­”æ–‡ã®æ„Ÿæƒ…ã‚’åˆ†é¡ã—ã¦ãã ã•ã„ã€‚

å¿œç­”æ–‡: {response_text}

é¸æŠè‚¢ï¼ˆemotion_keyã®ã¿ã‚’1ã¤è¿”ã—ã¦ãã ã•ã„ï¼‰:
- passion: æ¨ã—ã¸ã®æƒ…ç†±ãƒ»æ„›
- cheer: èºå‹•çš„ãªå¿œæ´ãƒ»ã‚¨ãƒ¼ãƒ«
- gratitude_hug: æ„Ÿè¬ãƒ»å¹¸ç¦æ„Ÿï¼ˆæŠ±æ“ï¼‰
- reverence: æ„Ÿå‹•ãƒ»å°Šã•ï¼ˆæ‹ã‚€ï¼‰
- excitement_move: é«˜æšãƒ»ç¾å ´ç§»å‹•ï¼ˆãƒãƒ£ãƒªï¼‰
- support_financial: çŒ®èº«ãƒ»æ”¯æ´ï¼ˆã‚¹ãƒ‘ãƒãƒ£ï¼‰
- infatuation: å¿ƒé…”ãƒ»é­…äº†ï¼ˆç›®ãŒãƒãƒ¼ãƒˆï¼‰
- deeply_moved: æ„ŸéŠ˜ãƒ»è½æ¶™ï¼ˆæ„Ÿå‹•ã®æ¶™ï¼‰
- kindness: å—å®¹ãƒ»ç©ã‚„ã‹ãªæ„Ÿè¬ï¼ˆåˆæŒï¼‰
- joy: æ­“å–œãƒ»é”æˆæ„Ÿï¼ˆã‚„ã£ãŸã‚ï¼‰
- encouragement: æ¿€åŠ±ãƒ»ãƒšãƒ³ãƒ©ã‚¤ãƒˆå¿œæ´
- meal_time: é£Ÿäº‹ãƒ»æœŸå¾…ï¼ˆã„ãŸã ãã¾ã™ï¼‰

è©²å½“ã™ã‚‹æ„Ÿæƒ…ãŒãªã„å ´åˆã¯ "none" ã¨è¿”ã—ã¦ãã ã•ã„ã€‚
emotion_keyã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ï¼ˆèª¬æ˜ä¸è¦ï¼‰:"""


class AIGenerator:
    """
    Amazon Bedrockã‚’ä½¿ç”¨ã—ã¦ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã«åˆã£ãŸå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã‚¯ãƒ©ã‚¹
    
    Attributes:
        bedrock_client: boto3 Bedrock Runtimeã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        model_id: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ID
    """
    
    # Bedrockè¨­å®š
    # Claude Haiku 4.5ã¯Inference ProfileçµŒç”±ã§ã®ã¿å‘¼ã³å‡ºã—å¯èƒ½
    # ã¾ãŸã€temperatureã¨top_pã¯åŒæ™‚ã«æŒ‡å®šã§ããªã„
    DEFAULT_MODEL_ID = "jp.anthropic.claude-haiku-4-5-20251001-v1:0"
    DEFAULT_MAX_TOKENS = 200
    DEFAULT_TEMPERATURE = 0.7
    
    def __init__(
        self,
        bedrock_client,
        model_id: str = DEFAULT_MODEL_ID,
        max_tokens: int = DEFAULT_MAX_TOKENS,
        temperature: float = DEFAULT_TEMPERATURE,
    ):
        """
        AIGeneratorã‚’åˆæœŸåŒ–
        
        Args:
            bedrock_client: boto3 Bedrock Runtimeã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
            model_id: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ID
            max_tokens: æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
            temperature: æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        """
        self.bedrock_client = bedrock_client
        self.model_id = model_id
        self.max_tokens = max_tokens
        self.temperature = temperature
    
    def build_prompt(self, post_content: str) -> str:
        """
        ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        
        Args:
            post_content: å…ƒã®æŠ•ç¨¿å†…å®¹
        
        Returns:
            æ§‹ç¯‰ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        return PROMPT_TEMPLATE.format(post_content=post_content)
    
    def truncate_text(self, text: str, max_length: int = MAX_TEXT_LENGTH) -> str:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡å®šæ–‡å­—æ•°ä»¥å†…ã«åˆ‡ã‚Šè©°ã‚
        
        Args:
            text: åˆ‡ã‚Šè©°ã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            max_length: æœ€å¤§æ–‡å­—æ•°
        
        Returns:
            åˆ‡ã‚Šè©°ã‚ã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        if len(text) <= max_length:
            return text
        
        # ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’ä¿æŒã™ã‚‹ãŸã‚ã«ã€ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°éƒ¨åˆ†ã‚’æŠ½å‡º
        hashtags = "#ã•ã¤ã¾ã„ã‚‚ã®æ°‘ #ã³ã£ããˆã‚“ã˜ã‡ã‚‹"
        hashtag_len = len(hashtags)
        
        # ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’é™¤ã„ãŸæœ€å¤§é•·
        content_max_len = max_length - hashtag_len - 1  # ã‚¹ãƒšãƒ¼ã‚¹åˆ†
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’é™¤å»
        text_without_hashtags = text.replace(hashtags, "").strip()
        
        if len(text_without_hashtags) > content_max_len:
            # åˆ‡ã‚Šè©°ã‚ã¦ã€Œ...ã€ã‚’è¿½åŠ 
            truncated = text_without_hashtags[:content_max_len - 3] + "..."
            return f"{truncated} {hashtags}"
        
        return text
    
    def generate_response(
        self,
        post_content: str,
        post_type: str = "oshi",
    ) -> str:
        """
        æŠ•ç¨¿å†…å®¹ã«åŸºã¥ã„ã¦å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ
        
        Args:
            post_content: å…ƒã®æŠ•ç¨¿å†…å®¹
            post_type: "oshi" ã¾ãŸã¯ "group"
        
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ140æ–‡å­—ä»¥å†…ï¼‰
        """
        try:
            prompt = self.build_prompt(post_content)
            
            # Bedrock APIå‘¼ã³å‡ºã—ï¼ˆClaudeå½¢å¼ï¼‰
            # Claude Haiku 4.5ã§ã¯temperatureã¨top_pã‚’åŒæ™‚ã«æŒ‡å®šã§ããªã„
            request_body = {
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": self.max_tokens,
                "temperature": self.temperature,
                "messages": [
                    {
                        "role": "user",
                        "content": prompt,
                    }
                ],
            }
            
            response = self.bedrock_client.invoke_model(
                modelId=self.model_id,
                body=json.dumps(request_body),
                contentType="application/json",
                accept="application/json",
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
            response_body = json.loads(response["body"].read())
            generated_text = response_body["content"][0]["text"].strip()
            
            # 140æ–‡å­—ä»¥å†…ã«åˆ‡ã‚Šè©°ã‚
            truncated_text = self.truncate_text(generated_text)
            
            logger.info(f"Generated response using model={self.model_id} for {post_type} post: {len(truncated_text)} chars")
            return truncated_text
            
        except Exception as e:
            logger.error(f"Failed to generate response: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ã‚’è¿”ã™
            return self._get_fallback_response(post_type)
    
    def _get_fallback_response(self, post_type: str) -> str:
        """
        ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ã‚’å–å¾—
        
        Args:
            post_type: "oshi", "group", "oshi_retweet", "group_retweet"
        
        Returns:
            ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ
        """
        if post_type == "oshi":
            return DEFAULT_RESPONSE_OSHI
        elif post_type == "oshi_retweet":
            return DEFAULT_RESPONSE_OSHI_RETWEET
        elif post_type == "group_retweet":
            return DEFAULT_RESPONSE_GROUP_RETWEET
        return DEFAULT_RESPONSE_GROUP
    
    def generate_retweet_response(self, post_type: str = "oshi") -> str:
        """
        ãƒªãƒ„ã‚¤ãƒ¼ãƒˆï¼ˆãƒªãƒã‚¹ãƒˆï¼‰ç”¨ã®å›ºå®šå¿œç­”ã‚’ç”Ÿæˆ
        
        Args:
            post_type: "oshi" ã¾ãŸã¯ "group"
        
        Returns:
            ãƒªãƒ„ã‚¤ãƒ¼ãƒˆç”¨å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ
        """
        if post_type == "oshi":
            return DEFAULT_RESPONSE_OSHI_RETWEET
        return DEFAULT_RESPONSE_GROUP_RETWEET
    
    def classify_emotion(self, response_text: str) -> Optional[str]:
        """
        å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…ã‚’åˆ†é¡
        
        Args:
            response_text: åˆ†é¡ã™ã‚‹å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ
        
        Returns:
            æ„Ÿæƒ…ã‚­ãƒ¼ï¼ˆemotion_keyï¼‰ã€åˆ†é¡å¤±æ•—æ™‚ã¯None
        """
        try:
            prompt = EMOTION_CLASSIFICATION_PROMPT.format(response_text=response_text)
            
            request_body = {
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": 50,
                "temperature": 0.0,  # æ±ºå®šçš„ãªå¿œç­”ã‚’å¾—ã‚‹ãŸã‚
                "messages": [
                    {
                        "role": "user",
                        "content": prompt,
                    }
                ],
            }
            
            response = self.bedrock_client.invoke_model(
                modelId=self.model_id,
                body=json.dumps(request_body),
                contentType="application/json",
                accept="application/json",
            )
            
            response_body = json.loads(response["body"].read())
            emotion_key = response_body["content"][0]["text"].strip().lower()
            
            # æœ‰åŠ¹ãªæ„Ÿæƒ…ã‚­ãƒ¼ã‹ãƒã‚§ãƒƒã‚¯
            valid_keys = {
                "passion", "cheer", "gratitude_hug", "reverence",
                "excitement_move", "support_financial", "infatuation",
                "deeply_moved", "kindness", "joy", "encouragement", "meal_time"
            }
            
            if emotion_key in valid_keys:
                logger.info(f"Classified emotion: {emotion_key}")
                return emotion_key
            elif emotion_key == "none":
                logger.info("Emotion classification returned 'none'")
                return None
            else:
                logger.warning(f"Unknown emotion key returned: {emotion_key}")
                return None
                
        except Exception as e:
            logger.error(f"Failed to classify emotion: {e}")
            return None
